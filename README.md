```markdown
# ğŸ” DocuMind â€“ Secure Retrieval-Augmented Generation API

RAGGuard is a secure, user-isolated Retrieval-Augmented Generation (RAG) system built with **FastAPI**, **FAISS**, and **OpenAI**. It allows authenticated users to upload documents, build vector indexes (FAISS), and ask natural language questions using OpenAI's GPT models â€“ all protected with **JWT authentication**.

---

## ğŸš€ Features

- âœ… JWT-based user authentication
- âœ… Document upload support (PDF, DOCX, TXT)
- âœ… FAISS vector index per user
- âœ… Contextual Q&A via OpenAI GPT (RAG)
- âœ… Swagger UI (`/docs`) with secure Bearer token auth
- âœ… Customizable prompt templates
- ğŸ” User isolation: only access your own files and embeddings

---

## ğŸ“ Directory Structure

```

rag\_guard/
â”œâ”€â”€ main.py                # FastAPI app entry point
â”œâ”€â”€ auth.py                # JWT config and secret loading
â”œâ”€â”€ file\_handler.py        # Upload and save user files
â”œâ”€â”€ rag\_engine.py          # Indexing and GPT-based querying
â”œâ”€â”€ embedding\_store.py     # FAISS save/load + embeddings
â”œâ”€â”€ storage/               # User data (organized per user\_id)
â”‚   â””â”€â”€ user\_xyz/
â”œâ”€â”€ .env                   # Secrets like API keys
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md

````

---

## ğŸ”§ Requirements

- Python 3.8+
- OpenAI API key
- Virtual environment

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/yourusername/ragguard.git
cd ragguard
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
````

---

## ğŸ” Environment Setup

Create a `.env` file:

```env
OPENAI_API_KEY=your_openai_key_here
JWT_SECRET_KEY=your_secret_key_here
```

> ğŸ’¡ Generate a strong secret using:
> `python -c "import secrets; print(secrets.token_urlsafe(32))"`

---

## ğŸƒ Run the Server

```bash
uvicorn main:app --reload
```

Then open:
ğŸ”— [http://localhost:8000/docs](http://localhost:8000/docs) â€” Swagger UI

---

## ğŸ§ª Example Workflow (Swagger)

1. ğŸ” **POST `/login/`**

   * username: `demo`
   * password: `demo123`

2. âœ… Copy the returned token â†’ click **"Authorize"** â†’ paste:

   ```
   Bearer <your_token>
   ```

3. ğŸ“ **POST `/upload/`** â€” Upload PDF, DOCX, or TXT file

4. ğŸ¤– **POST `/query/`** â€” Ask a question (optional: customize `system_prompt`)

---

## ğŸ” Prompt Customization

The `/query/` endpoint accepts an optional `system_prompt` field to guide the LLM response tone and style.

Examples:

```text
You are a lawyer. Answer with legal precision.
Explain in plain English for a 10-year-old.
Summarize in bullet points.
```

---

## ğŸ›¡ï¸ Security

* All endpoints (except `/login`) require JWT Bearer token.
* Each user's documents and vector index are stored separately.
* Prompt inputs are sanitized by OpenAI, but additional checks are encouraged for production.

---

## ğŸ“š Tech Stack

* [FastAPI](https://fastapi.tiangolo.com/)
* [FAISS](https://github.com/facebookresearch/faiss)
* [OpenAI API](https://platform.openai.com/)
* [fastapi-jwt-auth](https://github.com/IndominusByte/fastapi-jwt-auth)

---

## ğŸ“Œ TODO

* [ ] Add user registration
* [ ] Support multi-language documents
* [ ] Stream LLM responses
* [ ] Integrate with Chroma or Pinecone
* [ ] Web frontend (optional)

---

## ğŸ“ License

MIT License â€“ Use, modify, and share freely.

---

## ğŸ¤– Made with AI and FastAPI â¤ï¸

```

---

Would you like a `Dockerfile` or GitHub Actions workflow to package and deploy this next?
```
